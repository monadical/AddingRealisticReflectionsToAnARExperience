/*
See LICENSE folder for this sampleâ€™s licensing information.

Abstract:
Main view controller for the AR experience.
*/

import ARKit
import SceneKit
import UIKit

class ViewController: UIViewController, ARSCNViewDelegate, ARSessionDelegate {
    
    // MARK: IBOutlets
    
    @IBOutlet var sceneView: ARSCNView!
    @IBOutlet weak var sessionInfoLabel: UILabel!
    @IBOutlet weak var sessionInfoView: UIVisualEffectView!
    @IBOutlet weak var textureModeSelectionControl: UISegmentedControl!
    
    // MARK: - ARKit Configuration Properties
    
    // Model of shiny sphere that is added to the scene
    var virtualObjectModel: SCNNode = {
        guard let sceneURL = Bundle.main.url(forResource: "sphere", withExtension: "scn", subdirectory: "Models.scnassets/sphere"),
            let referenceNode = SCNReferenceNode(url: sceneURL) else {
                fatalError("can't load virtual object")
        }
        referenceNode.load()
        
        return referenceNode
    }()
    
    // MARK: - Environment Texturing Configuration
    
    /// The virtual object that the user interacts with in the scene.
    var virtualObject: SCNNode?
    /// An environment probe for shading that virtual object.
    var environmentProbeAnchor: AREnvironmentProbeAnchor?
    /// A fallback environment probe encompassing the whole scene.
    var sceneEnvironmentProbeAnchor: AREnvironmentProbeAnchor?
    /// Place environment probes manually or allow ARKit to place them automatically.
    var currentTexturingMode: ARWorldTrackingConfiguration.EnvironmentTexturing = .automatic
    /// Indicates whether manually placed probes need updating.
    var requiresProbeRefresh = true
    /// Tracks timing of manual probe updates to prevent updating too frequently.
    var lastProbeAnchorUpdateTime: TimeInterval = 0
    /// Indicates whether ARKit has provided an environment texture.
    var isEnvironmentTextureAvailable = false
    
    /// The latest screen touch position when a pan gesture is active
    var lastPanTouchPosition: CGPoint?

    // MARK: - View Controller Life Cycle
    
    override func viewDidLoad() {
        super.viewDidLoad()
        sceneView.delegate = self
        sceneView.session.delegate = self
        
        switch currentTexturingMode {
        case .manual:
            textureModeSelectionControl.selectedSegmentIndex = 1
        case .automatic:
            textureModeSelectionControl.selectedSegmentIndex = 0
        default:
            fatalError("This app supports only manual and automatic environment texturing.")
        }
    }

    /// - Tag: RunARSession
    override func viewDidAppear(_ animated: Bool) {
        super.viewDidAppear(animated)
        
        // Prevent the screen from dimming to avoid interrupting the AR experience.
        UIApplication.shared.isIdleTimerDisabled = true

        // Start the AR session with automatic environment texturing.
        
        let configuration = ARWorldTrackingConfiguration()
        configuration.planeDetection = .horizontal
        configuration.environmentTexturing = .automatic
        sceneView.session.run(configuration)
    }
    
    override func viewWillDisappear(_ animated: Bool) {
        super.viewWillDisappear(animated)

        sceneView.session.pause()
    }

    // MARK: - Session management
    
    @IBAction func changeTextureMode(_ sender: UISegmentedControl) {
        if sender.selectedSegmentIndex == 0 {
            currentTexturingMode = .automatic
            environmentProbeAnchor = nil
        } else {
            currentTexturingMode = .manual
            requiresProbeRefresh = true
        }
        // Remove anchors and change texturing mode
        resetTracking(changeTextureMode: true)
    }
    
    @IBAction func restartExperience() {
        virtualObject?.removeFromParentNode()
        virtualObject = nil
        
        resetTracking()
    }
    
    /// Runs the session with a new AR configuration to change modes or reset the experience.
    func resetTracking(changeTextureMode: Bool = false) {
        let configuration = ARWorldTrackingConfiguration()
        configuration.planeDetection = .horizontal
        configuration.environmentTexturing = currentTexturingMode
        
        let session = sceneView.session
        if changeTextureMode {
            // Remove existing environment probe anchors.
            session.currentFrame?.anchors
                .filter { $0 is AREnvironmentProbeAnchor }
                .forEach { session.remove(anchor: $0) }

            // Don't reset tracking when changing modes in the same session.
            session.run(configuration)
        } else {
            session.run(configuration, options: [.resetTracking, .removeExistingAnchors])
        }
        
        isEnvironmentTextureAvailable = false
        sceneEnvironmentProbeAnchor = nil
    }
    
    /// Updates the UI to provide feedback on the state of the AR experience.
    func updateSessionInfoLabel(for frame: ARFrame, trackingState: ARCamera.TrackingState) {
        let message: String?
        
        switch trackingState {
        case .notAvailable:
            message = "Tracking Unavailable"
        case .limited(.excessiveMotion):
            message = "Tracking Limited\nExcessive motion - Try slowing down your movement, or reset the session."
        case .limited(.insufficientFeatures):
            message = "Tracking Limited\nLow detail - Try pointing at a flat surface, or reset the session."
        case .limited(.initializing):
            message = "Initializing"
        case .limited(.relocalizing):
            message = "Recovering from interruption"
        case .normal where virtualObject == nil:
            if isEnvironmentTextureAvailable {
                message = "Tap to place a sphere, then tap or drag to move it or pinch to scale it."
            } else {
                message = "Generating environment texture."
            }
        default:
            message = nil
        }
        
        // Show the message, or hide the label if there's no message.
        DispatchQueue.main.async {
            UIView.animate(withDuration: 0.25) {
                self.sessionInfoLabel.text = message
                if message != nil {
                    self.sessionInfoView.alpha = 1
                } else {
                    self.sessionInfoView.alpha = 0
                }
            }
        }
    }
    
    // MARK: - Environment Texturing
    
    /// - Tag: ManualProbePlacement
    func updateEnvironmentProbe(atTime time: TimeInterval) {
        // Update the probe only if the object has been moved or scaled,
        // only when manually placed, not too often.
        guard let object = virtualObject,
            currentTexturingMode == .manual,
            time - lastProbeAnchorUpdateTime >= 1.0,
            requiresProbeRefresh
            else { return }
        
        // Remove existing probe anchor, if any.
        if let probeAnchor = self.environmentProbeAnchor {
            sceneView.session.remove(anchor: probeAnchor)
            self.environmentProbeAnchor = nil
        }
        
        // Make sure the probe encompasses the object and provides some surrounding area to appear in reflections.
        var extent = object.extents * object.simdScale
        extent.x *= 3 // Reflect an area 3x the width of the object.
        extent.z *= 3 // Reflect an area 3x the depth of the object.
        
        // Also include some vertical area around the object, but keep the bottom of the probe at the
        // bottom of the object so that it captures the real-world surface underneath.
        let verticalOffset = float3(0, extent.y, 0)
        let transform = float4x4(translation: object.simdPosition + verticalOffset)
        extent.y *= 2
        
        // Create the new environment probe anchor and add it to the session.
        let probeAnchor = AREnvironmentProbeAnchor(transform: transform, extent: extent)
        sceneView.session.add(anchor: probeAnchor)
        
        // Remember state to prevent updating the environment probe too often.
        environmentProbeAnchor = probeAnchor
        lastProbeAnchorUpdateTime = CACurrentMediaTime()
        requiresProbeRefresh = false
    }
    
    /// - Tag: FallbackEnvironmentProbe
    func updateSceneEnvironmentProbe(for frame: ARFrame) {
        if sceneEnvironmentProbeAnchor == nil && currentTexturingMode == .manual {
            // Create an environment probe anchor with room-sized extent to act as fallback when the probe anchor of
            // an object is removed and added during translation and scaling
            let probeAnchor = AREnvironmentProbeAnchor(name: "sceneProbe", transform: matrix_identity_float4x4, extent: float3(5))
            sceneView.session.add(anchor: probeAnchor)
            sceneEnvironmentProbeAnchor = probeAnchor
        }
    }

    // MARK: - ARSCNViewDelegate
    
    func renderer(_ renderer: SCNSceneRenderer, updateAtTime time: TimeInterval) {
        updateEnvironmentProbe(atTime: time)
    }
    
    func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {
        // Check for whether any environment textures have been generated.
        guard let envProbeAnchor = anchor as? AREnvironmentProbeAnchor, !isEnvironmentTextureAvailable
            else { return }
        
        isEnvironmentTextureAvailable = envProbeAnchor.environmentTexture != nil
    }
    
    // MARK: - ARSessionObserver
    
    func session(_ session: ARSession, cameraDidChangeTrackingState camera: ARCamera) {
        guard let frame = session.currentFrame else { fatalError("ARSession should have an ARFrame") }
        updateSessionInfoLabel(for: frame, trackingState: camera.trackingState)
    }
    
    func session(_ session: ARSession, didFailWithError error: Error) {
        resetTracking()
    }
    
    func sessionShouldAttemptRelocalization(_ session: ARSession) -> Bool {
        return true
    }
    
    // MARK: ARSessionDelegate
    
    func session(_ session: ARSession, didUpdate frame: ARFrame) {
        updateSceneEnvironmentProbe(for: frame)
        updateSessionInfoLabel(for: frame, trackingState: frame.camera.trackingState)
    }

    // MARK: Virtual Object gesture interaction
    
    @IBAction func didPan(_ gesture: UIPanGestureRecognizer) {
        guard let object = virtualObject else { return }
        
        switch gesture.state {
        case .changed:
            let translation = gesture.translation(in: sceneView)
            
            let previousPosition = lastPanTouchPosition ?? CGPoint(sceneView.projectPoint(object.position))
            // Calculate the new touch position
            let currentPosition = CGPoint(x: previousPosition.x + translation.x, y: previousPosition.y + translation.y)
            if let hitTestResult = sceneView.smartHitTest(currentPosition) {
                object.simdPosition = hitTestResult.worldTransform.translation
                // Refresh the probe as the object keeps moving
                requiresProbeRefresh = true
            }
            lastPanTouchPosition = currentPosition
            // reset the gesture's translation
            gesture.setTranslation(.zero, in: sceneView)
        default:
            // Clear the current position tracking.
            lastPanTouchPosition = nil
        }
    }
    
    @IBAction func didTap(_ gesture: UITapGestureRecognizer) {
        // Allow placing objects only when ARKit tracking is in a good state for hit testing,
        // and environment texture is available (to prevent undesirable changes in reflected texture).
        guard let camera = sceneView.session.currentFrame?.camera, case .normal = camera.trackingState, isEnvironmentTextureAvailable else { return }
        let touchLocation = gesture.location(in: sceneView)
        
        if let object = virtualObject {
            if let hitTestResult = sceneView.smartHitTest(touchLocation) {
                // Teleport the object to wherever the user touched the screen.
                object.simdPosition = hitTestResult.worldTransform.translation
                // Update the environment probe anchor when object is teleported.
                requiresProbeRefresh = true
            }
        } else {
            // Add the object to the scene at the tap location.
            DispatchQueue.global().async {
                self.place(self.virtualObjectModel, basedOn: touchLocation)
                
                // Newly added object requires an environment probe anchor.
                self.requiresProbeRefresh = true
            }
        }
    }
    
    @IBAction func didScale(_ gesture: UIPinchGestureRecognizer) {
        guard let object = virtualObject, gesture.state == .changed
            else { return }
        let newScale = object.simdScale * Float(gesture.scale)
        object.simdScale = newScale
        gesture.scale = 1.0
        // Realistic reflections require an environment probe extent based on the size of the object,
        // so update the environment probe when the object is resized.
        requiresProbeRefresh = true
    }
    
    func place(_ object: SCNNode, basedOn location: CGPoint) {
        guard let hitTestResult = sceneView.smartHitTest(location)
            else { return }
        sceneView.scene.rootNode.addChildNode(object)
        virtualObject = object // Remember that the object has been placed.
        
        object.simdPosition = hitTestResult.worldTransform.translation
        
        // Update the status UI to indicate the newly placed object.
        guard let frame = sceneView.session.currentFrame else { return }
        updateSessionInfoLabel(for: frame, trackingState: frame.camera.trackingState)
    }
}
